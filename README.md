# CAFA (Critical Assessment of Functional Annotation) for aphylo

This project is a response to the reviewers of our paper submitted to PLOS Comp
Bio. We will use the CAFA project to benchmark the quality of the predictions
generated by aphylo.

For the paper, we will be using CAFA 3.14, although CAFA 4 is in progress as I
write this (more info [here](https://www.synapse.org/#!Synapse:syn21035948/wiki/597155)).

CAFA 3.14 had a deadline Friday, April 20, 2018 11:59pm Baker Island Time Zone (UTC-12).
The closest Archived version of the GO dataset is from July 2nd, 2018. It can
be found here: https://zenodo.org/record/1205167 an alternative could be
the following dataset http://archive.geneontology.org/lite/2018-04-28/


## Implementation plan:

1. Use the most recent published version of CAFA

2. Apply the aphylo model to each challenge

3. Report (sounds simple)

In detail, we need to do the following:

1. Download the closets versions of PantherDB and GO to the submission
deadline of CAFA 3.14.

2. Filter the data so that we only use annotations that were publicly
available before the deadline.

3. Fit the model using all available information by type of ontology
(Biological Process, Molecular Function, Cellular component)

4. Make the predictions and preserve only those that we are confident
that the likelihood is different from .5

5. Download the GO (or UniProtKB data) that is closest to date in which




## Observations

Things to overcome: It seems that CAFA constists on raw sequences without
trees, which would require us to estimate the trees (we don't do that). An
alternative to this could be take the tree predictions that other models
have done and use those as a baseline to run our model.

Also important to remember, not all these methods are phylo based, which is
why there is no information about the phylogenies. I would be using either
PantherDB or UniProt to get the tree information. Also, it seems that the
experiment just indicates which proteins/genes need to be annotated, yet I
don't see what are the relevant annotations.

# The CAFA Challenge in a nutshell

- Participants are given a set of unannotated/incomplemetely annotated proteins.

- Participants are asked to make predictions until a date (using whatever data/method they want to train their models)

- After predictions are delivered, experimentally based annotations are accumulated in UniProtKB (~6 months).

- The methods are then evaluated on the discovered predictions registered in UniProtKB



